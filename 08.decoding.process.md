## Decoding process

### General decoding process

When film_grain_params_present is equal to 0, decoders shall produce output frames that are identical in all respects
and have the same output order as those produced by the decoding process specified herein.

When film_grain_params_present is equal to 1, a decoder shall implement a film grain synthesis process that
modifies the output arrays OutY, OutU, OutV. The reference film grain synthesis process is described in [section 7.18.3][].

When film_grain_params_present is equal to 1, a conformant decoder shall satisfy at least one of the following two options:

  1. A conformant decoder shall produce output frames that are identical in all respects and have the same output order as
  those produced by the decoding process specified herein including applying the exact film grain synthesis process
  as specified in [section 7.18.3][].

  2. A conformant decoder shall produce intermediate frames that are identical in all respects and have the same order as the
  frames produced by the process specified in [section 7.18.2][].
  In addition to that, a conformant decoder shall produce output frames that are in the same order and do not have perceptually
  significant differences with the frames produced by the reference film grain synthesis process specified in [section 7.18.3][]
  when applied to the input frames of the film grain synthesis process with the film grain parameters signaled for these frames.
  The decoder may also include optional processing steps which are applied to the intermediate frames produced by the
  process specified in [section 7.18.2][] and before the film grain synthesis process, resulting in the input frames of
  the film grain synthesis process. Such optional processing steps are
  beyond the scope of this specification. Otherwise, the intermediate frames are the input frames of the film grain synthesis process.
  The definition of "perceptually significant differences" is beyond the scope of this specification and may be specified,
  for example, by a service provider as part of their accreditation program.
  The film grain synthesis process applied by a conformant decoder should be feature complete with regards to
  the reference film grain synthesis process of [section 7.18.3][] including scaling strength of the film grain
  as a function of intensity according to the signaled parameters, same maximum AR lag, and similar
  modeling of correlation between luma and chroma and smoothing of transitions between blocks of grain when applicable.

**Note:** To ensure conformance, decoder manufacturers are advised to implement the film grain synthesis
process as specified in [section 7.18.3][].
One reason to choose the second conformance option is implementation of optional processing steps
between the output of [section 7.18.2][] and the film grain synthesis process, in which case there could be minor differences in the output with the reference film grain synthesis process of [section 7.18.3][]. Examples of these optional processing steps are algorithms improving output picture quality, such as de-banding filtering and coding artefacts removal.
{:.alert .alert-info }

**Note:**
Some applications, such as transcoding from AV1 to AV1, may use intermediate output frames of [section 7.18.2][] for transcoding. In such cases, the original film grain synthesis information may be adapted and inserted in the transcoded bitstream.
{:.alert .alert-info }

The input to this process is a sequence of open bitstream units (OBUs).

The output from this process is a sequence of decoded frames.

For each OBU in turn the syntax elements are extracted as specified in [section 5.3][].

The syntax tables include function calls indicating when the remaining decode processes are triggered.


### Output process

#### General

This process is invoked to prepare output frames.

If scalability is being used (OperatingPointIdc not equal to 0),
an application-specific function is called to decide whether this frame will be output.
If this function returns a value equal to 0, then this process terminates immediately.

**Note:** Applications that are displaying the decoded video are expected to only display
one frame from each temporal unit within the selected operating point.
This frame should be the highest spatial layer that is both within the operating point and present
within the temporal unit.
Other applications
may set their own policy about which frames are output.
{:.alert .alert-info }

The intermediate output preparation process specified in [section 7.18.2][] is invoked to prepare arrays OutY, OutU, and OutV, and the outputs are assigned to w, h, subX, and subY.

If film_grain_params_present is equal to 1 and apply_grain is equal to 1, then
the film grain synthesis process specified in [section 7.18.3][] is invoked with inputs of w, h, subX, and subY.
(This process modifies the output arrays OutY, OutU, OutV).

Finally, the frame to be output is defined to be the arrays OutY, OutU, OutV where the bit depth for each sample is BitDepth.

This frame to be output is the overall output of the decoding process and further processing (such as color conversion) is outside the scope of this specification.

For example, a real implementation might use these arrays to display the frame to the user, or a test system might save the arrays so the output can be verified.

**Note:** If NumPlanes is equal to 1, then the U and V planes should be ignored.
{:.alert .alert-info }

#### Intermediate output preparation process

The output of this process are the variables w, h, subX, and subY describing the format of the data in arrays OutY, OutU,
and OutV.

If show_existing_frame is equal to 1, then the decoder should copy OutY, OutU, and OutV from a previously decoded frame as follows:

  * The variable w is set equal to RefUpscaledWidth[ frame_to_show_map_idx ].

  * The variable h is set equal to RefFrameHeight[ frame_to_show_map_idx ].

  * The variable subX is set equal to RefSubsamplingX[ frame_to_show_map_idx ].

  * The variable subY is set equal to RefSubsamplingY[ frame_to_show_map_idx ].

  * The array OutY is w samples across by h samples down and the sample at
    location x samples across and y samples down is given by
    OutY[ y ][ x ] = FrameStore[ frame_to_show_map_idx ][ 0 ][ y ][ x ] with x = 0..w - 1
    and y = 0..h - 1.

  * The array OutU is (w + subX) \>\> subX samples across by (h + subY) \>\> subY
    samples down and the sample at location x samples across and y samples
    down is given by OutU[ y ][ x ] = FrameStore[ frame_to_show_map_idx ][ 1 ][ y ][ x ]
    with x = 0..((w + subX) \>\> subX) - 1 and y = 0..((h + subY) \>\> subY) - 1.

  * The array OutV is (w + subX) \>\> subX samples across by (h + subY) \>\> subY
    samples down and the sample at location x samples across and y samples
    down is given by OutV[ y ][ x ] = FrameStore[ frame_to_show_map_idx ][ 2 ][ x ][ y ]
    with x = 0..((w + subX) \>\> subX) - 1 and y = 0..((h + subY) \>\> subY) - 1.

  * The variable BitDepth is set equal to RefBitDepth[ frame_to_show_map_idx ].

  * The bit depth for each sample is BitDepth.

Otherwise (show_existing_frame is equal to 0), then the decoder should copy the
current frame as follows:

  * The variable w is set equal to UpscaledWidth.

  * The variable h is set equal to FrameHeight.

  * The variable subX is set equal to subsampling_x.

  * The variable subY is set equal to subsampling_y.

  * The array OutY is w samples across by h samples down and the sample at
    location x samples across and y samples down is given by
    OutY[ y ][ x ] = LrFrame[ 0 ][ y ][ x ] with x = 0..w - 1 and y = 0..h - 1.

  * The array OutU is (w + subX) \>\> subX samples across by (h + subY) \>\> subY
    samples down and the sample at location x samples across and y samples
    down is given by OutU[ y ][ x ] = LrFrame[ 1 ][ y ][ x ]
    with x = 0..((w + subX) \>\> subX) - 1 and y = 0..((h + subY) \>\> subY) - 1.

  * The array OutV is (w + subX) \>\> subX samples across by (h + subY) \>\> subY
    samples down and the sample at location x samples across and y samples
    down is given by OutV[ y ][ x ] = LrFrame[ 2 ][ y ][ x ]
    with x = 0..((w + subX) \>\> subX) - 1 and y = 0..((h + subY) \>\> subY) - 1.

  * The bit depth for each sample is BitDepth.

The output of this process are the variables w, h, subX, and subY.

#### Film grain synthesis process

##### General

The inputs to this process are:

  * variables w and h specifying the width and height of the frame,

  * variables subX and subY specifying the subsampling parameters of the frame.

The process modifies the arrays OutY, OutU, OutV to add film grain noise as follows:

  1. The variable RandomRegister (used for generating pseudo-random numbers) is set equal to grain_seed.

  2. The variable GrainCenter is set equal to 128 \<\< (BitDepth - 8).

  3. The variable GrainMin is set equal to = -GrainCenter.

  4. The variable GrainMax is set equal to (256 \<\< (BitDepth - 8)) - 1 - GrainCenter.

  5. The generate grain process specified in [section 7.18.3.3][] is invoked.

  6. The scaling lookup initialization process specified in [section 7.18.3.4][] is invoked.

  7. The add noise process specified in [section 7.18.3.5][] is invoked with w, h, subX, and subY as inputs.

##### Random number process

The input to this process is a variable bits specifying the number of random bits to return.

The output of this process is a pseudo-random number based on the state in RandomRegister.

The process is specified as follows:

~~~~~ c
get_random_number( bits ) {
  r = RandomRegister
  bit = ((r >> 0) ^ (r >> 1) ^ (r >> 3) ^ (r >> 12)) & 1
  r = (r >> 1) | (bit << 15)
  result = (r >> (16 - bits)) & ((1 << bits) - 1)
  RandomRegister = r
  return result
}
~~~~~

The output of this process is the variable result.

##### Generate grain process

This process generates noise via an auto-regressive filter.

First an array LumaGrain 82 samples wide and 73 samples high of white noise is generated for luma as follows:

~~~~~ c
shift = 12 - BitDepth + grain_scale_shift
for ( y = 0; y < 73; y++ ) {
  for ( x = 0; x < 82; x++ ) {
    if ( num_y_points > 0 ) {
      g = Gaussian_Sequence[ get_random_number( 11 ) ]
    } else {
      g = 0
    }
    LumaGrain[ y ][ x ] = Round2( g, shift )
  }
}
~~~~~

where the function call get_random_number invokes the random number process specified in [section 7.18.3.2][].

Then an auto-regressive filter is applied to the white noise as follows:

~~~~~ c
shift = ar_coeff_shift_minus_6 + 6
for ( y = 3; y < 73; y++ ) {
  for ( x = 3; x < 82 - 3; x++ ) {
    s = 0
    pos = 0
    for ( deltaRow = -ar_coeff_lag; deltaRow <= 0; deltaRow++ ) {
      for ( deltaCol = -ar_coeff_lag; deltaCol <= ar_coeff_lag; deltaCol++ ) {
        if ( deltaRow == 0 && deltaCol == 0 )
          break
        c = ar_coeffs_y_plus_128[ pos ] - 128
        s += LumaGrain[ y + deltaRow ][ x + deltaCol ] * c
        pos++
      }
    }
    LumaGrain[ y ][ x ] = Clip3( GrainMin, GrainMax, LumaGrain[ y ][ x ] + Round2( s, shift ) )
  }
}
~~~~~

If mono_chrome is equal to 0,
the chroma grain is generated in a similar way, except the filtering includes a coefficient that introduces a correlation with the luma grain.

The variable chromaW (representing the width of the chroma noise array) is set equal to (subsampling_x ? 44 : 82).

The variable chromaH (representing the height of the chroma noise array) is set equal to (subsampling_y ? 38 : 73).

White noise arrays CbGrain and CrGrain chromaW samples wide and chromaH samples high are generated as follows:

~~~~~ c
shift = 12 - BitDepth + grain_scale_shift
RandomRegister = grain_seed ^ 0xb524
for ( y = 0; y < chromaH; y++ ) {
  for ( x = 0; x < chromaW; x++ ) {
    if ( num_cb_points > 0 || chroma_scaling_from_luma) {
      g = Gaussian_Sequence[ get_random_number( 11 ) ]
    } else {
      g = 0
    }
    CbGrain[ y ][ x ] = Round2( g, shift )
  }
}
RandomRegister = grain_seed ^ 0x49d8
for ( y = 0; y < chromaH; y++ ) {
  for ( x = 0; x < chromaW; x++ ) {
    if ( num_cr_points > 0 || chroma_scaling_from_luma) {
      g = Gaussian_Sequence[ get_random_number( 11 ) ]
    } else {
      g = 0
    }
    CrGrain[ y ][ x ] = Round2( g, shift )
  }
}
~~~~~

Then the auto-regressive filter is applied as follows:

~~~~~ c
shift = ar_coeff_shift_minus_6 + 6
for ( y = 3; y < chromaH; y++ ) {
  for ( x = 3; x < chromaW - 3; x++ ) {
    s0 = 0
    s1 = 0
    pos = 0
    for ( deltaRow = -ar_coeff_lag; deltaRow <= 0; deltaRow++ ) {
      for ( deltaCol = -ar_coeff_lag; deltaCol <= ar_coeff_lag; deltaCol++ ) {
        c0 = ar_coeffs_cb_plus_128[ pos ] - 128
        c1 = ar_coeffs_cr_plus_128[ pos ] - 128
        if ( deltaRow == 0 && deltaCol == 0 ) {
          if ( num_y_points > 0 ) {
            luma = 0
            lumaX = ( (x - 3) << subsampling_x ) + 3
            lumaY = ( (y - 3) << subsampling_y ) + 3
            for ( i = 0; i <= subsampling_y; i++ )
              for ( j = 0; j <= subsampling_x; j++ )
                luma += LumaGrain[ lumaY + i ][ lumaX + j ]
            luma = Round2( luma, subsampling_x + subsampling_y )
            s0 += luma * c0
            s1 += luma * c1
          }
          break
        }
        s0 += CbGrain[ y + deltaRow ][ x + deltaCol ] * c0
        s1 += CrGrain[ y + deltaRow ][ x + deltaCol ] * c1
        pos++
      }
    }
    CbGrain[ y ][ x ] = Clip3( GrainMin, GrainMax, CbGrain[ y ][ x ] + Round2( s0, shift ) )
    CrGrain[ y ][ x ] = Clip3( GrainMin, GrainMax, CrGrain[ y ][ x ] + Round2( s1, shift ) )
  }
}
~~~~~

**Note:** When num_y_points is equal to 0, this process may use uninitialized values within ar_coeffs_y_plus_128 to compute LumaGrain.
However, LumaGrain will never be read in this case so it does not matter what values are constucted.
Similarly, when num_cr_points/num_cb_points are equal to 0 and chroma_scaling_from_luma is equal to 0, the CbGrain/CrGrain arrays will never be read.
{:.alert .alert-info }

##### Scaling lookup initialization process

This process computes 3 lookup tables for the different color components.

Each lookup table ScalingLut[ plane ] contains 256 entries constructed by a piecewise linear interpolation of the given points as follows:

~~~~~ c
for ( plane = 0; plane < NumPlanes; plane++ ) {
    if ( plane == 0 || chroma_scaling_from_luma )
        numPoints = num_y_points
    else if ( plane == 1 )
        numPoints = num_cb_points
    else
        numPoints = num_cr_points
    if ( numPoints == 0 ) {
        for ( x = 0; x < 256; x++ ) {
            ScalingLut[ plane ][ x ] = 0
        }
    } else {
        for ( x = 0; x < get_x( plane, 0 ); x++ ) {
            ScalingLut[ plane ][ x ] = get_y( plane, 0 )
        }
        for ( i = 0; i < numPoints - 1; i++ ) {
            deltaY = get_y( plane, i + 1 ) - get_y( plane, i )
            deltaX = get_x( plane, i + 1 ) - get_x( plane, i )
            delta = deltaY * ( ( 65536 + (deltaX >> 1) ) / deltaX )
            for ( x = 0; x < deltaX; x++ ) {
                v = get_y( plane, i ) + ( ( x * delta + 32768 ) >> 16 )
                ScalingLut[ plane ][ get_x( plane, i )  + x ] = v
            }
        }
        for ( x = get_x( plane, numPoints - 1 ); x < 256; x++ ) {
            ScalingLut[ plane ][ x ] = get_y( plane, numPoints - 1 )
        }
    }
}
~~~~~

where the functions get_x and get_y return the coordinates for a specific point and are specified as:

~~~~~ c
get_x( plane, i ) {
    if ( plane == 0 || chroma_scaling_from_luma )
        return point_y_value[ i ]
    else if ( plane == 1 )
        return point_cb_value[ i ]
    else
        return point_cr_value[ i ]
}

get_y( plane, i ) {
    if ( plane == 0 || chroma_scaling_from_luma )
        return point_y_scaling[ i ]
    else if ( plane == 1 )
        return point_cb_scaling[ i ]
    else
        return point_cr_scaling[ i ]
}
~~~~~

##### Add noise synthesis process

The inputs to this process are:

  * variables w and h specifying the width and height of the frame,

  * variables subX and subY specifying the subsampling parameters of the frame.

This process combines the film grain with the image data.

First an array of noise data noiseStripe is generated for each 32 luma sample high stripe of the image.

noiseStripe[ lumaNum ][ 0 ] is 34 samples high and w samples wide
(a few additional samples across are actually written to the array, but these are never read) and contains noise for the luma component.

noiseStripe[ lumaNum ][ 1 ] and noiseStripe[ lumaNum ][ 2 ] are (34 \>\> subY) samples high and Round2(w, subX) samples wide and contain noise for the chroma components.

noiseStripe represents the result of constructing square grain blocks and blending horizontally adjacent blocks together
(although blending is only applied if overlap_flag is equal to 1) and is constructed as follows:

~~~~~ c
lumaNum = 0
for ( y = 0; y < (h + 1)/2 ; y += 16 ) {
  RandomRegister = grain_seed
  RandomRegister ^= ((lumaNum * 37 + 178) & 255) << 8
  RandomRegister ^= ((lumaNum * 173 + 105) & 255)
  for ( x = 0; x < (w + 1)/2 ; x += 16 ) {
    rand = get_random_number( 8 )
    offsetX = rand >> 4
    offsetY = rand & 15
    for ( plane = 0 ; plane < NumPlanes; plane++ ) {
      planeSubX = ( plane > 0) ? subX : 0
      planeSubY = ( plane > 0) ? subY : 0
      planeOffsetX = planeSubX ? 6 + offsetX : 9 + offsetX * 2
      planeOffsetY = planeSubY ? 6 + offsetY : 9 + offsetY * 2
      for ( i = 0; i < 34 >> planeSubY ; i++ ) {
        for ( j = 0; j < 34 >> planeSubX ; j++ ) {
          if ( plane == 0 )
            g = LumaGrain[ planeOffsetY + i ][ planeOffsetX + j ]
          else if ( plane == 1 )
            g = CbGrain[ planeOffsetY + i ][ planeOffsetX + j ]
          else
            g = CrGrain[ planeOffsetY + i ][ planeOffsetX + j ]
          if ( planeSubX == 0 ) {
            if ( j < 2 && overlap_flag && x > 0 ) {
              old = noiseStripe[ lumaNum ][ plane ][ i ][ x * 2 + j ]
              if ( j == 0 ) {
                g = old * 27 + g * 17
              } else {
                g = old * 17 + g * 27
              }
              g = Clip3( GrainMin, GrainMax, Round2(g, 5) )
            }
            noiseStripe[ lumaNum ][ plane ][ i ][ x * 2 + j ] = g
          } else {
            if ( j == 0 && overlap_flag && x > 0 ) {
              old = noiseStripe[ lumaNum ][ plane ][ i ][ x + j ]
              g = old * 23 + g * 22
              g = Clip3( GrainMin, GrainMax, Round2(g, 5) )
            }
            noiseStripe[ lumaNum ][ plane ][ i ][ x + j ] = g
          }
        }
      }
    }
  }
  lumaNum++
}
~~~~~

Then the noise stripes are blended together to form a noise image noiseImage as follows:

~~~~~ c
for ( plane = 0; plane < NumPlanes; plane++ ) {
  planeSubX = ( plane > 0) ? subX : 0
  planeSubY = ( plane > 0) ? subY : 0
  for ( y = 0; y < ( (h + planeSubY) >> planeSubY ) ; y++ ) {
    lumaNum = y >> ( 5 - planeSubY )
    i = y - (lumaNum << ( 5 - planeSubY ) )
    for ( x = 0; x < ( (w + planeSubX) >> planeSubX) ; x++ ) {
      g = noiseStripe[ lumaNum ][ plane ][ i ][ x ]
      if ( planeSubY == 0 ) {
        if ( i < 2 && lumaNum > 0 && overlap_flag ) {
          old = noiseStripe[ lumaNum - 1 ][ plane ][ i + 32 ][ x ]
          if ( i == 0 ) {
            g = old * 27 + g * 17
          } else {
            g = old * 17 + g * 27
          }
          g = Clip3( GrainMin, GrainMax, Round2(g, 5) )
        }
      } else {
        if ( i < 1 && lumaNum > 0 && overlap_flag ) {
          old = noiseStripe[ lumaNum - 1 ][ plane ][ i + 16 ][ x ]
          g = old * 23 + g * 22
          g = Clip3( GrainMin, GrainMax, Round2(g, 5) )
        }
      }
      noiseImage[ plane ][ y ][ x ] = g
    }
  }
}
~~~~~

**Note:** Although this process is specified in terms of full size noiseStripe and noiseImage arrays,
the reference code shows how it is possible to implement the grain synthesis with just 2 line buffers for luma,
and 1 line buffer for each chroma component.
{:.alert .alert-info }

Finally, the noise is blended with the original image data as follows:

~~~~~ c
if ( clip_to_restricted_range ) {
  minValue = 16 << (BitDepth - 8)
  maxLuma = 235 << (BitDepth - 8)
  if ( matrix_coefficients == MC_IDENTITY )
    maxChroma = maxLuma
  else
    maxChroma = 240 << (BitDepth - 8)
} else {
  minValue = 0
  maxLuma = (256 << (BitDepth - 8)) - 1
  maxChroma = maxLuma
}
ScalingShift = grain_scaling_minus_8 + 8
for ( y = 0; y < ( (h + subY) >> subY) ; y++ ) {
  for ( x = 0; x < ( (w + subX) >> subX) ; x++ ) {
    lumaX = x << subX
    lumaY = y << subY
    lumaNextX = Min( lumaX + 1, w - 1 )
    if ( subX )
      averageLuma = Round2( OutY[ lumaY ][ lumaX ] + OutY[ lumaY ][ lumaNextX ], 1 )
    else
      averageLuma = OutY[ lumaY ][ lumaX ]
    if ( num_cb_points > 0 || chroma_scaling_from_luma ) {
      orig = OutU[ y ][ x ]
      if ( chroma_scaling_from_luma ) {
        merged = averageLuma
      } else {
        combined = averageLuma * ( cb_luma_mult - 128 ) + orig * ( cb_mult - 128 )
        merged = Clip1( ( combined >> 6 ) + ( (cb_offset - 256 ) << (BitDepth - 8) ) )
      }
      noise = noiseImage[ 1 ][ y ][ x ]
      noise = Round2( scale_lut( 1, merged ) * noise, ScalingShift )
      OutU[ y ][ x ] = Clip3( minValue, maxChroma, orig + noise )
    }

    if ( num_cr_points > 0 || chroma_scaling_from_luma) {
      orig = OutV[ y ][ x ]
      if ( chroma_scaling_from_luma ) {
        merged = averageLuma
      } else {
        combined = averageLuma * ( cr_luma_mult - 128 ) + orig * ( cr_mult - 128 )
        merged = Clip1( ( combined >> 6 ) + ( (cr_offset - 256 ) << (BitDepth - 8) ) )
      }
      noise = noiseImage[ 2 ][ y ][ x ]
      noise = Round2( scale_lut( 2, merged ) * noise, ScalingShift )
      OutV[ y ][ x ] = Clip3( minValue, maxChroma, orig + noise )
    }
  }
}
for ( y = 0; y < h ; y++ ) {
  for ( x = 0; x < w ; x++ ) {
    orig = OutY[ y ][ x ]
    noise = noiseImage[ 0 ][ y ][ x ]
    noise = Round2( scale_lut( 0, orig ) * noise, ScalingShift )
    if ( num_y_points > 0 ) {
      OutY[ y ][ x ] = Clip3( minValue, maxLuma, orig + noise )
    }
  }
}
~~~~~

where scale_lut is a function that performs a piecewise linear interpolation into the appropriate scaling table.
The scale_lut function is specified as follows:

~~~~~ c
scale_lut( plane, index ) {
  shift = BitDepth - 8
  x = index >> shift
  rem = index - ( x << shift )
  if ( BitDepth == 8 || x == 255) {
    return ScalingLut[ plane ][ x ]
  } else {
    start = ScalingLut[ plane ][ x ]
    end = ScalingLut[ plane ][ x + 1 ]
    return start + Round2( (end - start) * rem, shift )
  }
}
~~~~~


### Motion field motion vector storage process

This process applies some filtering and reordering to the motion vectors to prepare them
for storage as part of the reference frame update process.

The following applies for row = 0..MiRows-1, for col = 0..MiCols-1:

~~~~~ c
    MfRefFrames[ row ][ col ] = NONE
    MfMvs[ row ][ col ][ 0 ] = 0
    MfMvs[ row ][ col ][ 1 ] = 0
    for ( list = 0; list < 2; list++ ) {
        r = RefFrames[ row ][ col ][ list ]
        if ( r > INTRA_FRAME ) {
            refIdx = ref_frame_idx[ r - LAST_FRAME ]
            dist = get_relative_dist( RefOrderHint[ refIdx ], OrderHint )
            if ( dist < 0 ) {
                mvRow = Mvs[ row ][ col ][ list ][ 0 ]
                mvCol = Mvs[ row ][ col ][ list ][ 1 ]
                if ( Abs( mvRow ) <= REFMVS_LIMIT && Abs( mvCol ) <= REFMVS_LIMIT ) {
                    MfRefFrames[ row ][ col ] = r
                    MfMvs[ row ][ col ][ 0 ] = mvRow
                    MfMvs[ row ][ col ][ 1 ] = mvCol
                }
            }
        }
    }
~~~~~

**Note:** Although this process stores all the motion vectors into MfMvs, only the values where row and col are both odd will affect the decoding process.
{:.alert .alert-info }


